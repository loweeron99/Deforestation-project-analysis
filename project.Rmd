---
title: "Untitled"
author: "group"
date: "2023-03-02"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Kmeans}
library(tidyverse)
df = read.csv("../data/Boston_housing_price.csv", header = TRUE)
df <- df[, -1]

# Normalize the data
boston_norm <- scale(df)

# Compute and plot the within-cluster sum of squares for different numbers of clusters
wcss <- vector("numeric", length = 10)
for (i in 1:10) {
  set.seed(123)
  k <- kmeans(boston_norm, i)
  wcss[i] <- k$tot.withinss
}
plot(1:10, wcss, type = "b", xlab = "Number of clusters", ylab = "Within-cluster sum of squares")

# Identify the optimal number of clusters using the elbow method (first differences)
diffs <- diff(wcss)
elbow <- which(diffs == min(diffs)) + 1
cat("The optimal number of clusters based on first differences is", elbow, "\n")

# Identify the optimal number of clusters using the elbow method (second differences)
second_diffs <- diff(diffs)
elbow <- which(second_diffs == min(second_diffs)) + 1
cat("The optimal number of clusters based on second differences is", elbow, "\n")

# Perform k-means clustering with the optimal number of clusters found
set.seed(123)
k <- kmeans(boston_norm, elbow)

# Compute the cluster means for each variable by cluster
df_means <- df %>% mutate(group = k$cluster) %>% group_by(group) %>% summarize_all(mean)
df_means

```

```{r To check whether 9 cluster is suitable}
# Perform PCA on the normalized data
pca <- prcomp(boston_norm, center = TRUE, scale. = TRUE)

# Extract the first two principal components
pc1 <- pca$x[, 1]
pc2 <- pca$x[, 2]

# Create a scatter plot of the first two principal components colored by cluster
ggplot(data = data.frame(pc1, pc2, group = as.factor(k$cluster)), aes(x = pc1, y = pc2, color = group)) + 
  geom_point() + 
  labs(title = "K-means clustering results with optimal number of clusters", x = "Principal component 1", y = "Principal component 2")

#9 clusters too much overlap cant differentiate. So choose 2 clusters instead
```

```{r Kmeans with 2 cluster}
# Perform k-means clustering with the optimal number of clusters found
set.seed(123)
k <- kmeans(boston_norm, 2)

# Perform PCA on the normalized data
pca <- prcomp(boston_norm, center = TRUE, scale. = TRUE)

# Extract the first two principal components
pc1 <- pca$x[, 1]
pc2 <- pca$x[, 2]

# Create a scatter plot of the first two principal components colored by cluster
ggplot(data = data.frame(pc1, pc2, group = as.factor(k$cluster)), aes(x = pc1, y = pc2, color = group)) + 
  geom_point(size = 3, alpha = 0.7) + 
  labs(title = "K-means clustering results with optimal number of clusters", x = "Principal component 1", y = "Principal component 2")

# Print the cluster centers
print(k$centers)

# Add the cluster assignments to the original dataset
df$cluster <- k$cluster

# Calculate summary statistics for each cluster
df_summary <- df %>% 
  group_by(cluster) %>% 
  summarize_all(mean)
  
# Print the summary statistics
print(df_summary)
```

```{r Using logestic regression to identify the top 5 variables}
# Load necessary libraries
library(tidyverse)
library(caret)
library(glmnet)

# Create a binary target variable
df$target <- ifelse(df$cluster == 1, 1, 0)

# Split the data into training and testing sets
set.seed(123)
split <- createDataPartition(df$target, p = 0.8, list = FALSE)
train <- df[split,]
test <- df[-split,]

# Select the independent variables
x_train <- model.matrix(target ~ . - cluster, data = train)[,-1]
y_train <- train$target

x_test <- model.matrix(target ~ . - cluster, data = test)[,-1]
y_test <- test$target

# Perform logistic regression with LASSO regularization
set.seed(123)
cv_fit <- cv.glmnet(x_train, y_train, family = "binomial", alpha = 1, nfolds = 10)

# Select the best lambda
best_lambda <- cv_fit$lambda.min

# Train the model with the best lambda
lasso_model <- glmnet(x_train, y_train, family = "binomial", alpha = 1, lambda = best_lambda)

# Get the coefficients
coefficients <- coef(lasso_model)

# Convert the coefficients to a data frame
coefficients_df <- as.data.frame(as.matrix(coefficients))

# Remove the first row (intercept)
coefficients_df <- coefficients_df[-1, , drop = FALSE]

# Add row names as a new column and reset row names
coefficients_df$Variable <- row.names(coefficients_df)
row.names(coefficients_df) <- NULL

# Rename the coefficient column
names(coefficients_df)[1] <- "Coefficient"

# Display the top 5 most important variables
top_5_variables <- coefficients_df %>%
  arrange(desc(abs(Coefficient))) %>%
  head(5)

print(top_5_variables)

# Add cluster assignments to the original data
df_with_clusters <- df %>% mutate(cluster = k$cluster)

# Compute the cluster means for each variable by cluster
df_means <- df_with_clusters %>% group_by(cluster) %>% summarize_all(mean)

# Create scatter plots for the top 5 most important variables using medv as the y variable
for (i in 1:5) {
  variable_name <- top_5_variables$Variable[i]
  ggplot(df_means, aes_string(x = variable_name, y = "medv", color = "factor(cluster)")) +
    geom_point(size = 4) +
    theme_minimal() +
    labs(x = variable_name, y = "medv", color = "Cluster") +
    ggtitle(paste("Scatter plot of", variable_name, "and medv (cluster means)"))
  print(last_plot())
}


```


```{r Hierarchical}
library(tidyverse)

df = read.csv("../data/Boston_housing_price.csv",header = TRUE)
df <- df[, -1]
boston_norm <- scale(df)

get_hclust_summary <- function(linkage_method) {
  dist_mat <- dist(x = boston_norm, method = "euclidean")
  hc <- hclust(d = dist_mat, method = linkage_method)
  cutree_hc <- cutree(hc, k = 2)
  df_hclust <- df %>% mutate(k = as.factor(cutree_hc))
  df_hclust_summary <- df_hclust %>% group_by(k) %>% summarize(across(everything(), mean))
  return(df_hclust_summary)
}

df_hclust_single_summary <- get_hclust_summary("single")
df_hclust_complete_summary <- get_hclust_summary("complete")
df_hclust_average_summary <- get_hclust_summary("average")
df_hclust_ward_summary <- get_hclust_summary("ward.D2")

```

```{r}
# Function to plot scatter plots of the top 5 most important variables with medv
plot_top_variables <- function(data, method) {
  for (i in 1:5) {
    variable_name <- top_5_variables$Variable[i]
    ggplot(data, aes_string(x = variable_name, y = "medv", color = "factor(k)")) +
      geom_point(size = 4) +
      theme_minimal() +
      labs(x = variable_name, y = "medv", color = "Cluster") +
      ggtitle(paste("Scatter plot of", variable_name, "and medv using", method, "linkage"))
    print(last_plot())
  }
}

# Plot scatter plots for different linkage methods
plot

# Plot scatter plots for different linkage methods
plot_top_variables(df_hclust_single_summary, "single")
plot_top_variables(df_hclust_complete_summary, "complete")
plot_top_variables(df_hclust_average_summary, "average")
plot_top_variables(df_hclust_ward_summary, "Ward")
```


```{r DBscan}
# Load required packages
library(dbscan)
library(tidyverse)

# Load data
df <- read.csv("../data/Boston_housing_price.csv", header = TRUE)
df <- df[, -1]
boston_norm <- scale(df)

# Function to plot k-distance graph
plotdist <- function(data, minPts) {
  k_dist <- kNNdist(data, k = minPts)
  k_dist_sorted <- sort(k_dist, decreasing = FALSE)
  data.frame(x = 1:length(k_dist_sorted), y = k_dist_sorted) %>%
    ggplot(aes(x = x, y = y)) +
    geom_point() +
    geom_line() +
    labs(x = "Index", y = "Distance") +
    theme_bw()
}

# Plot k-distance graph
plotdist(data = boston_norm, minPts = 15)

# Choose an appropriate eps value based on the k-distance graph
eps_value <- 5.2  # Change this value according to the k-distance graph

# Compute DBSCAN clustering
dbscan_fit <- dbscan(boston_norm, eps = eps_value, minPts = 15)

# View cluster assignments
dbscan_fit$cluster

# Compute cluster means for each variable by cluster
df_dbscan_summary <- df %>%
  mutate(k = as.factor(dbscan_fit$cluster)) %>%
  group_by(k) %>%
  summarize(across(everything(), mean))

df_dbscan_summary


```



```{r}
# Add cluster assignments to the original data
df_with_clusters <- df %>% mutate(cluster = as.factor(dbscan_fit$cluster))

# Compute the cluster means for each variable by cluster
df_means <- df_with_clusters %>% group_by(cluster) %>% summarize_all(mean)

for (i in 1:5) {
  variable_name <- top_5_variables$Variable[i]
  ggplot(df_means, aes_string(x = variable_name, y = "medv", color = "factor(cluster)")) +
    geom_point(size = 4) +
    theme_minimal() +
    labs(x = variable_name, y = "medv", color = "Cluster") +
    ggtitle(paste("Scatter plot of", top_5_variables$Variable[i], "and medv (DBSCAN cluster means)"))
  print(last_plot())
}
```







```{r regression analysis}
library(tidyverse)
# Load and normalize the Boston housing price dataset
df <- read.csv("../data/Boston_housing_price.csv", header = TRUE)
df<-df[,-1] # that is the ID not related 
df <- scale(df) %>% as.data.frame(df)
# Split the data into 80% training and 20% testing sets
set.seed(123)
id <- sample(x=nrow(df), size=nrow(df)*0.8)
train <- df[id,]
test <- df[-id,]

lm1 <- lm(formula=medv~., data=train)
summary(lm1)


df <- df[, -3]   #drop indus cause highest p-value >0.05
df <- scale(df) %>% as.data.frame(df)

# Split the data into 80% training and 20% testing sets
set.seed(123)
id <- sample(x=nrow(df), size=nrow(df)*0.8)
train <- df[id,]
test <- df[-id,]

lm1 <- lm(formula=medv~., data=train)
summary(lm1)

df <- df[, -6]   #drop age cause highest p-value >0.05
df <- scale(df) %>% as.data.frame(df)

# Split the data into 80% training and 20% testing sets
set.seed(123)
id <- sample(x=nrow(df), size=nrow(df)*0.8)
train <- df[id,]
test <- df[-id,]

lm1 <- lm(formula=medv~., data=train)
summary(lm1)


eval.metrics.linreg <- function(actual, predicted) {
  residual <- actual - predicted
  mse <- mean(residual ^ 2)
  mae <- mean(abs(residual))
  rmse <-  sqrt(mse)
  mape <- mean(abs(residual / actual)) 
  
  data.frame(
    RMSE = rmse,
    MAPE = mape
  )
}

# Train the final model on the entire training set
lm1 <- lm(formula = medv ~ ., data = train)

# Evaluation metrics for test data
actual <- test$medv
predicted <- predict(lm1, newdata = test)
eval.metrics.linreg(actual, predicted)



```


```{r using tree regression}
library(rpart)
library(rpart.plot)
library(caret)
library(tidyverse)
library(Metrics)
library(ipred)
library(gbm)

df <- read.csv("../data/Boston_housing_price.csv", header = TRUE)
df <- df[,-1]
df <- scale(df) %>% as.data.frame(df)

# Split the data into 80% training and 20% testing sets
set.seed(123)
id <- sample(x=nrow(df), size=nrow(df)*0.8)
train <- df[id,]
test <- df[-id,]


# Decision tree regression
tree <- train(medv ~ ., 
              data = train, 
              method = "rpart",
              metric = "RMSE",
              trControl = trainControl(method = "cv", number = 5))
tree$results$RMSE
predict_tree <- predict(tree, test)
rmse(test$medv, predict_tree)
mape(test$medv, predict_tree)

# Bagging
tree_bagging <- train(medv ~ ., 
                      data = train, 
                      method = "treebag",
                      metric = "RMSE",
                      trControl = trainControl(method = "cv", number = 5),
                      coob = TRUE, 
                      nbagg = 25, 
                      keepX = TRUE)
predict_bagging <- predict(tree_bagging, test)
rmse(test$medv, predict_bagging)
mape(test$medv, predict_bagging)

# Boosting
tree_boosting <- train(medv ~ ., 
                       data = train, 
                       method = "gbm",
                       distribution = "gaussian",
                       metric = "RMSE",
                       trControl = trainControl(method = "cv", number = 5))
predict_boosting <- predict(tree_boosting, test)
rmse(test$medv, predict_boosting)
mape(test$medv, predict_boosting)

# Random forest
tree_rf <- train(medv ~ .,
                  data = train,
                  method = "rf",
                  importance = TRUE,
                  metric = "RMSE",
                  trControl = trainControl(method = "cv", number = 5))
predict_rf <- predict(tree_rf, test)
rmse(test$medv, predict_rf)
mape(test$medv, predict_rf)

```


```{r fine tuning parameters to see if got any effect}

# Fine-tuning Decision Tree
tree <- train(medv ~ ., 
              data = train, 
              method = "rpart",
              metric = "RMSE",
              trControl = trainControl(method = "cv", number = 5),
              tuneGrid = expand.grid(cp = seq(0.001, 0.1, length.out = 10))) # Fine-tune complexity parameter (cp)
predict_tree <- predict(tree, test)
rmse(test$medv, predict_tree)
mape(test$medv, predict_tree)

# Custom grid search for Bagging
nbagg_values <- c(10, 25, 50, 100)
cv_folds <- 5
set.seed(123)

cv_results <- list()

for (nbagg in nbagg_values) {
  # Perform cross-validation for the current nbagg value
  cv_model <- train(medv ~ .,
                    data = train,
                    method = "treebag",
                    trControl = trainControl(method = "cv", number = cv_folds),
                    nbagg = nbagg)
  
  # Store the cross-validated RMSE and nbagg value
  cv_results[[as.character(nbagg)]] <- list(RMSE = cv_model$results$RMSE[1], nbagg = nbagg)
}

# Find the best nbagg value based on the lowest cross-validated RMSE
best_nbagg <- nbagg_values[which.min(sapply(cv_results, function(x) x$RMSE))]

# Train the bagging model with the best nbagg value
tree_bagging <- train(medv ~ .,
                      data = train,
                      method = "treebag",
                      trControl = trainControl(method = "cv", number = cv_folds),
                      nbagg = best_nbagg)

# Predict and evaluate the bagging model with the best nbagg value
predict_bagging <- predict(tree_bagging, test)
rmse(test$medv, predict_bagging)
mape(test$medv, predict_bagging)


# Boosting
tree_boosting <- train(medv ~ ., 
                       data = train, 
                       method = "gbm",
                       distribution = "gaussian",
                       metric = "RMSE",
                       trControl = trainControl(method = "cv", number = 5),
                       tuneGrid = expand.grid(interaction.depth = c(1, 3, 5, 7),
                                              n.trees = c(50, 100, 150),
                                              shrinkage = c(0.1, 0.05), # Add shrinkage values
                                              n.minobsinnode = c(10, 20))) # Add n.minobsinnode values
predict_boosting <- predict(tree_boosting, test)
rmse(test$medv, predict_boosting)
mape(test$medv, predict_boosting)


# Random forest
tune_grid_rf <- expand.grid(mtry = c(2, 4, 6, 8))

tree_rf <- train(medv ~ .,
                 data = train,
                 method = "rf",
                 importance = TRUE,
                 metric = "RMSE",
                 trControl = trainControl(method = "cv", number = 5),
                 tuneGrid = tune_grid_rf)

predict_rf <- predict(tree_rf, test)
rmse(test$medv, predict_rf)
mape(test$medv, predict_rf)


```

```{r Comparing across the different methods}
# Performance metrics for the decision tree model
rmse_tree <- rmse(test$medv, predict_tree)
mape_tree <- mape(test$medv, predict_tree)

# Performance metrics for the bagging model
rmse_bagging <- rmse(test$medv, predict_bagging)
mape_bagging <- mape(test$medv, predict_bagging)

# Performance metrics for the boosting model
rmse_boosting <- rmse(test$medv, predict_boosting)
mape_boosting <- mape(test$medv, predict_boosting)

# Performance metrics for the random forest model
rmse_rf <- rmse(test$medv, predict_rf)
mape_rf <- mape(test$medv, predict_rf)

# Performance metrics for the linear regression model
actual <- test$medv
predicted <- predict(lm1, newdata = test)
metrics_lm <- eval.metrics.linreg(actual, predicted)
rmse_lm <- metrics_lm$RMSE
mape_lm <- metrics_lm$MAPE


# Create a data frame to store the performance metrics
model_comparison <- data.frame(
  Model = c("Decision Tree", "Bagging", "Boosting", "Random Forest", "Linear Regression"),
  RMSE = c(rmse_tree, rmse_bagging, rmse_boosting, rmse_rf, rmse_lm),
  MAPE = c(mape_tree, mape_bagging, mape_boosting, mape_rf, mape_lm)
)

# Print the data frame
model_comparison


```


